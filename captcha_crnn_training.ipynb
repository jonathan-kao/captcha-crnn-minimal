{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPe46Otdiye3"
      },
      "source": [
        "# Captcha CRNN training pipeline (including pretraining).\n",
        "\n",
        "This notebook includes two stages:\n",
        "1. Single-letter classification pretraining (SimpleCNN).\n",
        "2. Load pretrained CNN weights and train a CRNN + CTC decoder for CAPTCHA recognition.\n",
        "\n",
        "**Assumes CAPTCHAs contain only lowercase English letters, no digits.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "def get_unique_filename(base_name):\n",
        "    \"\"\"\n",
        "    Automatically finds non-conflicting filenames;\n",
        "    if the base name exists, suffixes like _1, _2, etc. are added.\n",
        "    \"\"\"\n",
        "    if not os.path.exists(base_name):\n",
        "        return base_name\n",
        "\n",
        "    name, ext = os.path.splitext(base_name)\n",
        "    i = 1\n",
        "    while True:\n",
        "        new_name = f\"{name}_{i}{ext}\"\n",
        "        if not os.path.exists(new_name):\n",
        "            return new_name\n",
        "        i += 1"
      ],
      "metadata": {
        "id": "ozuMjS2bTPue"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TxRgeo9Biye7"
      },
      "outputs": [],
      "source": [
        "# Character set defined as lowercase letters plus a blank token\n",
        "import string\n",
        "CHARS = string.ascii_lowercase\n",
        "BLANK = \"-\"\n",
        "\n",
        "char2idx = {BLANK: 0}\n",
        "for i, c in enumerate(CHARS, 1):\n",
        "    char2idx[c] = i\n",
        "idx2char = {i: c for c, i in char2idx.items()}\n",
        "NUM_CLASSES = len(char2idx)\n",
        "print(f\"Classes: {NUM_CLASSES}, Characters: {CHARS}\")\n",
        "\n",
        "BLANK_INDEX = 0  # Corresponds to the CTC blank token\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdGdysvNiye9"
      },
      "outputs": [],
      "source": [
        "# SimpleCNN: Single-Character Classifier\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self, n_classes):\n",
        "        super().__init__()\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(1, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(), nn.MaxPool2d(2),\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(), nn.AdaptiveAvgPool2d(1)\n",
        "        )\n",
        "        self.fc = nn.Linear(256, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        return self.fc(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S4q0dXyxiye_"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class SingleLetterDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.samples = []\n",
        "        self.transform = transform\n",
        "        for label in os.listdir(root_dir):\n",
        "            label_path = os.path.join(root_dir, label)\n",
        "            if not os.path.isdir(label_path): continue\n",
        "            for file in os.listdir(label_path):\n",
        "                if file.endswith('.png') or file.endswith('.jpg'):\n",
        "                    self.samples.append((os.path.join(label_path, file), label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label = self.samples[idx]\n",
        "        image = Image.open(path).convert(\"L\")\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "        return image, char2idx[label]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "khp8Rxckiye_"
      },
      "outputs": [],
      "source": [
        "def train_single_letter(model, dataset, device, epochs=10):\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch.optim as optim\n",
        "    model.to(device)\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=True)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        total_loss = 0\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            out = model(x)\n",
        "            loss = criterion(out, y)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_single_letter_accuracy(model, dataset, device=\"cpu\"):\n",
        "    from torch.utils.data import DataLoader\n",
        "    model.eval()\n",
        "    model.to(device)\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=64, shuffle=False)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for x, y in loader:\n",
        "            x, y = x.to(device), y.to(device)\n",
        "            output = model(x)\n",
        "            pred = output.argmax(dim=1)\n",
        "            correct += (pred == y).sum().item()\n",
        "            total += y.size(0)\n",
        "\n",
        "    acc = correct / total\n",
        "    print(f\"✅ Single letter acc: {acc:.2%}\")\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "9RMgmsLsnPM3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2qb92xgviye-"
      },
      "outputs": [],
      "source": [
        "# CRNN + CTC\n",
        "class CRNN(nn.Module):\n",
        "    def __init__(self, img_h, n_channels, n_classes, rnn_hidden=256):\n",
        "        super().__init__()\n",
        "        self.cnn = nn.Sequential(\n",
        "            nn.Conv2d(n_channels, 64, 3, padding=1), nn.BatchNorm2d(64), nn.ReLU(True), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(64, 128, 3, padding=1), nn.BatchNorm2d(128), nn.ReLU(True), nn.MaxPool2d(2, 2),\n",
        "            nn.Conv2d(128, 256, 3, padding=1), nn.BatchNorm2d(256), nn.ReLU(True), nn.MaxPool2d((2,1), (2,1)),\n",
        "        )\n",
        "        self.rnn_input = 256 * (img_h // 8)\n",
        "        self.rnn = nn.LSTM(self.rnn_input, rnn_hidden, num_layers=2, bidirectional=True, batch_first=True)\n",
        "        self.fc = nn.Linear(rnn_hidden * 2, n_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        conv = self.cnn(x)\n",
        "        b, c, h, w = conv.size()\n",
        "        conv = conv.permute(0, 3, 1, 2)\n",
        "        rnn_in = conv.view(b, w, c * h)\n",
        "        rnn_out, _ = self.rnn(rnn_in)\n",
        "        out = self.fc(rnn_out)\n",
        "        return out.log_softmax(2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fErhTezwiye-"
      },
      "outputs": [],
      "source": [
        "def load_cnn_weights_into_crnn(crnn_model, cnn_model):\n",
        "    \"\"\"\n",
        "    Transfers convolutional feature weights from SimpleCNN to the CRNN's CNN module.\n",
        "    \"\"\"\n",
        "    cnn_state = cnn_model.conv.state_dict()\n",
        "    crnn_state = crnn_model.cnn.state_dict()\n",
        "\n",
        "    # Filters for matching parameter keys\n",
        "    filtered_state = {k: v for k, v in cnn_state.items() if k in crnn_state}\n",
        "    crnn_state.update(filtered_state)\n",
        "\n",
        "    crnn_model.cnn.load_state_dict(crnn_state)\n",
        "    print(\"✅ Successfully loaded convolutional weights from SimpleCNN into the CRNN!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "import os\n",
        "\n",
        "class CaptchaDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        \"\"\"\n",
        "        root_dir: the image folder, e.g., \"captchas\", where filenames follow the pattern abcd.png.\n",
        "        \"\"\"\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.samples = []\n",
        "\n",
        "        for fname in os.listdir(root_dir):\n",
        "            if fname.endswith(\".png\"):\n",
        "                label = fname.split(\".\")[0]\n",
        "                self.samples.append((os.path.join(root_dir, fname), label))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.samples)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        path, label_str = self.samples[idx]\n",
        "        img = Image.open(path).convert(\"L\")\n",
        "\n",
        "        if self.transform:\n",
        "            img = self.transform(img)\n",
        "\n",
        "        label = torch.tensor([char2idx[c] for c in label_str], dtype=torch.long)\n",
        "        return img, label, torch.tensor(len(label))\n"
      ],
      "metadata": {
        "id": "6ZARbzBuwzhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_fn(batch):\n",
        "    imgs, labels, label_lens = zip(*batch)\n",
        "    imgs = torch.stack(imgs, 0)  # (B, C, H, W)\n",
        "    label_lens = torch.tensor(label_lens, dtype=torch.long)  # 1D tensor with length equal to batch size\n",
        "    labels = torch.cat(labels)\n",
        "    return imgs, labels, label_lens\n"
      ],
      "metadata": {
        "id": "KlBrAHKxxXFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_crnn(model, dataset, device=\"cuda\", epochs=20, freeze_cnn_epochs=5):\n",
        "    from torch.utils.data import DataLoader\n",
        "    import torch.optim as optim\n",
        "\n",
        "    loader = DataLoader(dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "    ctc_loss = nn.CTCLoss(blank=BLANK_INDEX, zero_infinity=True)\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "\n",
        "        # Whether to freeze CNN (only for the first few epochs).\n",
        "        if epoch < freeze_cnn_epochs:\n",
        "            for param in model.cnn.parameters():\n",
        "                param.requires_grad = False\n",
        "        else:\n",
        "            for param in model.cnn.parameters():\n",
        "                param.requires_grad = True\n",
        "\n",
        "        total_loss = 0\n",
        "        for imgs, labels, label_lens in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            logits = model(imgs)  # current order (B, T, C)\n",
        "            logits = logits.permute(1, 0, 2)  # rearrange into (T, B, C)\n",
        "            log_probs = nn.functional.log_softmax(logits, dim=2)\n",
        "\n",
        "            input_lens = torch.full(size=(logits.size(1),), fill_value=logits.size(0), dtype=torch.long)\n",
        "\n",
        "            loss = ctc_loss(log_probs, labels, input_lens, label_lens)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            total_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}, Loss: {total_loss/len(loader):.4f}\",\n",
        "              \"(CNN frozen)\" if epoch < freeze_cnn_epochs else \"\")\n"
      ],
      "metadata": {
        "id": "uZXCvQBKv1Js"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "\n",
        "def decode_prediction(pred_indices, idx2char, blank_idx=0):\n",
        "    \"\"\"\n",
        "    Applies simple CTC decoding (removing repeated characters and blanks)\n",
        "    pred_indices: List[int], the index sequence predicted by the model\n",
        "    \"\"\"\n",
        "    decoded = []\n",
        "    prev = None\n",
        "    for idx in pred_indices:\n",
        "        if idx != blank_idx and idx != prev:\n",
        "            decoded.append(idx2char[idx])\n",
        "        prev = idx\n",
        "    return ''.join(decoded)\n",
        "\n",
        "def test_crnn(model, dataset, device, idx2char, batch_size=32, verbose=False):\n",
        "    from torch.utils.data import DataLoader\n",
        "\n",
        "    GREEN = \"\\033[92m\"\n",
        "    RED = \"\\033[91m\"\n",
        "    RESET = \"\\033[0m\"\n",
        "\n",
        "    model.eval()\n",
        "    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for imgs, labels, label_lens in loader:\n",
        "            imgs = imgs.to(device)\n",
        "            logits = model(imgs)\n",
        "\n",
        "            if logits.shape[0] == imgs.size(0):\n",
        "                logits = logits.permute(1, 0, 2)\n",
        "            log_probs = torch.nn.functional.log_softmax(logits, dim=2)\n",
        "\n",
        "            pred_indices = log_probs.argmax(dim=2).cpu().numpy().transpose(1, 0)\n",
        "            labels = labels.cpu().numpy()\n",
        "            label_lens = label_lens.cpu().numpy()\n",
        "\n",
        "            label_ptr = 0\n",
        "            for i in range(len(imgs)):\n",
        "                length = label_lens[i]\n",
        "                true_label_idx = labels[label_ptr:label_ptr + length]\n",
        "                label_ptr += length\n",
        "\n",
        "                pred_label_idx = pred_indices[i].tolist()\n",
        "                pred_text = decode_prediction(pred_label_idx, idx2char)\n",
        "                true_text = ''.join(idx2char[idx] for idx in true_label_idx)\n",
        "\n",
        "                if pred_text == true_text:\n",
        "                    correct += 1\n",
        "                    color = GREEN\n",
        "                else:\n",
        "                    color = RED\n",
        "\n",
        "                if verbose:\n",
        "                    print(f\"{color}Predict: {pred_text} | GT: {true_text}{RESET}\")\n",
        "\n",
        "                total += 1\n",
        "\n",
        "    acc = correct / total if total > 0 else 0\n",
        "    print(f\"\\n✅ Test Accuracy: {acc*100:.2f}% ({correct}/{total})\")\n",
        "    return acc\n"
      ],
      "metadata": {
        "id": "sJMenMWCzU7v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!unzip /content/single_char_images.zip -d /content/single_char_images\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "mTD9GmD4jHa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torchvision.transforms as T\n",
        "\n",
        "transform = T.Compose([\n",
        "    T.Resize((30, 100)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "from torch.utils.data import DataLoader\n",
        "single_dataset = SingleLetterDataset(\"single_char_images\", transform)\n"
      ],
      "metadata": {
        "id": "qN6KCikIlEBS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "cnn = SimpleCNN(n_classes=len(char2idx))\n",
        "train_single_letter(cnn, single_dataset, device=\"cuda\", epochs=30)\n",
        "\n",
        "cnn_filename = get_unique_filename(\"cnn_pretrained.pth\")\n",
        "torch.save(cnn.state_dict(), cnn_filename)\n",
        "print(f\"✅ Model saved as: {cnn_filename}\")\n",
        "files.download(cnn_filename)\n"
      ],
      "metadata": {
        "id": "Y4UTl9yOlG_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!unzip /content/single_char_test_images.zip -d /content/single_char_test_images\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "Estf3WZHrGPy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((30, 100)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "test_single_dataset = SingleLetterDataset(\"single_char_test_images\", transform)\n"
      ],
      "metadata": {
        "id": "5g7EfF80RRMN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "cnn = SimpleCNN(n_classes=len(char2idx))\n",
        "cnn.load_state_dict(torch.load(cnn_filename, map_location=\"cuda\"))\n",
        "cnn.to(\"cuda\")\n",
        "cnn.eval()\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "3h2VMXp9PX-C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_single_letter_accuracy(cnn, single_dataset, device=\"cuda\")\n",
        "evaluate_single_letter_accuracy(cnn, test_single_dataset, device=\"cuda\")\n"
      ],
      "metadata": {
        "id": "lFRcgRcpnRIx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!unzip /content/train_captchas.zip -d /content/train_captchas\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "d9G_ikhKwWeq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((30, 120)),  # Size of 4-letter CAPTCHA images\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "captcha_dataset = CaptchaDataset(\"train_captchas\", transform)\n"
      ],
      "metadata": {
        "id": "mYt1kn_9v_ft"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load CNN weights into CRNN\n",
        "cnn = SimpleCNN(n_classes=len(char2idx))\n",
        "cnn.load_state_dict(torch.load(cnn_filename))\n",
        "\n",
        "crnn = CRNN(img_h=30, n_channels=1, n_classes=NUM_CLASSES)\n",
        "load_cnn_weights_into_crnn(crnn, cnn)\n"
      ],
      "metadata": {
        "id": "fKOrNpUGuvyZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "train_crnn(crnn, captcha_dataset, device=\"cuda\", epochs=40, freeze_cnn_epochs=5)\n",
        "\n",
        "crnn_filename = get_unique_filename(\"crnn.pth\")\n",
        "torch.save(crnn.state_dict(), crnn_filename)\n",
        "print(f\"✅ Model saved as: {crnn_filename}\")\n",
        "files.download(crnn_filename)\n"
      ],
      "metadata": {
        "id": "nML54ao5wAV-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "!unzip /content/test_captchas.zip -d /content/test_captchas\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "ZGN_kGjnNcce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = T.Compose([\n",
        "    T.Resize((30, 120)),\n",
        "    T.ToTensor()\n",
        "])\n",
        "\n",
        "test_captcha_dataset = CaptchaDataset(\"test_captchas\", transform)"
      ],
      "metadata": {
        "id": "sHzADbgzNhFQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from IPython.display import clear_output\n",
        "crnn = CRNN(img_h=30, n_channels=1, n_classes=NUM_CLASSES)\n",
        "crnn.load_state_dict(torch.load(crnn_filename, map_location=\"cuda\"))\n",
        "crnn.to(\"cuda\")\n",
        "crnn.eval()\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "_TobEY8EQsdx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_accuracy = test_crnn(crnn, captcha_dataset, device=\"cuda\", idx2char=idx2char)\n",
        "test_accuracy = test_crnn(crnn, test_captcha_dataset, device=\"cuda\", idx2char=idx2char, verbose=True)\n"
      ],
      "metadata": {
        "id": "Vx8W110szV6l"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.x"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}